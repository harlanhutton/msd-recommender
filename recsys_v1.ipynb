{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql.functions import col, explode\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.parquet('train_sample1.parquet')\n",
    "ratings.createOrReplaceTempView('ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-------------+--------------+\n",
      "|count|__index_level_0__|user_id_numer|track_id_numer|\n",
      "+-----+-----------------+-------------+--------------+\n",
      "|    2|              107|     222596.0|        3947.0|\n",
      "|    1|              156|     238051.0|        4071.0|\n",
      "|    1|              342|     267078.0|        2582.0|\n",
      "|    1|              406|      41261.0|        5217.0|\n",
      "|    1|              443|      41261.0|        2556.0|\n",
      "|    2|              574|       4240.0|         731.0|\n",
      "|    1|              610|       4240.0|        8026.0|\n",
      "|    5|              630|       4240.0|        3878.0|\n",
      "|    6|              956|       4240.0|         573.0|\n",
      "|    1|             1019|       4240.0|        9901.0|\n",
      "|    1|             1081|      12196.0|       82088.0|\n",
      "|    1|             1108|      12196.0|       67786.0|\n",
      "|    1|             1213|      12196.0|       67307.0|\n",
      "|    1|             1278|      12196.0|        5306.0|\n",
      "|    2|             1327|     254074.0|       16847.0|\n",
      "|    1|             1353|     273783.0|         128.0|\n",
      "|    5|             1509|     109747.0|        5218.0|\n",
      "|    1|             1546|     158779.0|       32203.0|\n",
      "|    2|             1565|     327879.0|       10024.0|\n",
      "|    3|             1858|      76953.0|          90.0|\n",
      "+-----+-----------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_id_numer\")\n",
    "indexed_prelim = indexer.fit(ratings).transform(ratings)\n",
    "\n",
    "indexer_2 = StringIndexer(inputCol=\"track_id\", outputCol=\"track_id_numer\")\n",
    "indexed = indexer_2.fit(indexed_prelim).transform(indexed_prelim)\n",
    "\n",
    "df_dropped = indexed.drop('user_id')\n",
    "df_dropped = df_dropped.drop('track_id')\n",
    "df_dropped.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = df_dropped.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 6.9732870424197895\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id_numer\", itemCol=\"track_id_numer\", ratingCol=\"count\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"count\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 song recommendations for each user\n",
    "\n",
    "### ADJUST FOR 500 SONGS \n",
    "\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each song\n",
    "songRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS WILL BE REMOVED ####\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = df_dropped.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "songs = df_dropped.select(als.getItemCol()).distinct().limit(3)\n",
    "songSubSetRecs = model.recommendForItemSubset(songs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|user_id_numer|     recommendations|\n",
      "+-------------+--------------------+\n",
      "|       262469|[{28588, 57.25669...|\n",
      "|        45953|[{50608, 246.8295...|\n",
      "|       278371|[{54627, 279.1140...|\n",
      "+-------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetRecs_col = userSubsetRecs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(userSubsetRecs_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noop = userSubsetRecs_col['recommendations'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ids = []\n",
    "play_counts = []\n",
    "for n in range(len(noop)):\n",
    "    song_ids.append(noop[n][0])\n",
    "    play_counts.append(noop[n][1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28588, 50608, 62245, 40636, 22981, 19750, 3595, 1757, 60450, 2930]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     recommendations|\n",
      "+--------------------+\n",
      "|[{28588, 57.25669...|\n",
      "|[{50608, 246.8295...|\n",
      "|[{54627, 279.1140...|\n",
      "+--------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(type(my_list))\n",
    "test = userSubsetRecs.select(['recommendations'][0]).show()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetRecs2 = userSubsetRecs.select(userSubsetRecs.user_id_numer,explode(userSubsetRecs.recommendations.track_id_numer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|user_id_numer|  col|\n",
      "+-------------+-----+\n",
      "|       262469|28588|\n",
      "|       262469|50608|\n",
      "|       262469|62245|\n",
      "|       262469|40636|\n",
      "|       262469|22981|\n",
      "|       262469|19750|\n",
      "|       262469| 3595|\n",
      "|       262469| 1757|\n",
      "|       262469|60450|\n",
      "|       262469| 2930|\n",
      "|        45953|50608|\n",
      "|        45953|48884|\n",
      "|        45953|16999|\n",
      "|        45953|12756|\n",
      "|        45953| 5314|\n",
      "|        45953|15646|\n",
      "|        45953|67294|\n",
      "|        45953|31449|\n",
      "|        45953|67491|\n",
      "|        45953|46876|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "userSubsetRecs2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "#userSubsetRecs2.toPandas().set_index('user_id_numer').T.to_dict('list')\n",
    "#usesrSubsetRecs2 = userSubsetRecs2.toPandas()\n",
    "#userSubsetRecs2.groupby('user_id_numer')['col'].apply(lambda g: g.values.tolist()).to_dict()\n",
    "\n",
    "#userSubsetRecs2.groupBy(\"user_id_numer\").agg(first(\"age\", ignoreNulls = true) as \"age\".orderBy(\"id\")\n",
    "\n",
    "test = userSubsetRecs2.groupby('user_id_numer').agg(func.collect_list('col').alias(\"col\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{262469: [28588, 50608, 62245, 40636, 22981, 19750, 3595, 1757, 60450, 2930],\n",
       " 45953: [50608, 48884, 16999, 12756, 5314, 15646, 67294, 31449, 67491, 46876],\n",
       " 278371: [54627, 26092, 49471, 15646, 13067, 22906, 10400, 5314, 2360, 95422]}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = test.collect()\n",
    "df_dict = [{r['user_id_numer']: r['col']} for r in df_dict]\n",
    "dict((key,d[key]) for d in df_dict for key in d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
