{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "from pyspark.sql.functions import col, explode\n",
    "import pandas as pd\n",
    "# import findspark \n",
    "# findspark.init()  \n",
    "# import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#for later --conf spark.sql.catalogImplementation=hive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSample = spark.read.parquet('train_sample1.parquet')\n",
    "testSample = spark.read.parquet('test_sample1.parquet')\n",
    "trainSample.createOrReplaceTempView('trainSample')\n",
    "testSample.createOrReplaceTempView('testSample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_obj_1 = StringIndexer(inputCol=\"user_id\", outputCol=\"user_id_numer\").setHandleInvalid(\"keep\")\n",
    "indexer_model_1 = indexer_obj_1.fit(trainSample)\n",
    "indexer_df_1 = indexer_model_1.transform(trainSample)\n",
    "\n",
    "indexer_obj_2 = StringIndexer(inputCol=\"track_id\", outputCol=\"track_id_numer\").setHandleInvalid(\"keep\")\n",
    "indexer_model_2= indexer_obj_2.fit(indexer_df_1)\n",
    "indexer_df_2 = indexer_model_2.transform(indexer_df_1)\n",
    "\n",
    "train_df = indexer_df_2.drop('user_id')\n",
    "train_df= train_df.drop('track_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_1 = indexer_model_1.transform(testSample)\n",
    "test_df_2= indexer_model_2.transform(test_df_1)\n",
    "\n",
    "test_df = test_df_2.drop('user_id')\n",
    "test_df= test_df.drop('track_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-------------+--------------+\n",
      "|count|__index_level_0__|user_id_numer|track_id_numer|\n",
      "+-----+-----------------+-------------+--------------+\n",
      "|    1|               93|     334914.0|        2629.0|\n",
      "|    1|              259|     334914.0|        1648.0|\n",
      "|    1|              276|     334914.0|        5546.0|\n",
      "|    2|              305|     334914.0|        1686.0|\n",
      "|   30|              322|      99931.0|       84794.0|\n",
      "|    1|              359|      99933.0|        1766.0|\n",
      "|    2|              642|     334914.0|       47063.0|\n",
      "|    1|              701|      99999.0|       14041.0|\n",
      "|    1|              808|     334914.0|       69616.0|\n",
      "|    1|              984|     334914.0|       25893.0|\n",
      "|    1|              988|     334914.0|        1658.0|\n",
      "|    1|             1058|     334914.0|         447.0|\n",
      "|    1|             1095|     100063.0|         383.0|\n",
      "|    5|             1164|     100072.0|       18547.0|\n",
      "|    1|             1507|     334914.0|       79535.0|\n",
      "|    4|             1679|     334914.0|       85508.0|\n",
      "|    1|             1722|     334914.0|       12652.0|\n",
      "|    1|             1737|     100155.0|        4139.0|\n",
      "|    1|             1780|     334914.0|        5956.0|\n",
      "|    1|             1793|     334914.0|         686.0|\n",
      "+-----+-----------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 7.588528461264799\n"
     ]
    }
   ],
   "source": [
    "# Build the recommendation model using ALS on the training data\n",
    "# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"user_id_numer\", itemCol=\"track_id_numer\", ratingCol=\"count\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "model = als.fit(train_df)\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "# Evaluate the model by computing the RMSE on the test data\n",
    "\n",
    "# evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"count\",\n",
    "#                                 predictionCol=\"prediction\")\n",
    "# rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "# print(\"Root-mean-square error = \" + str(rmse))\n",
    "\n",
    "# Generate top 10 song recommendations for each user\n",
    "\n",
    "### ADJUST FOR 500 SONGS \n",
    "\n",
    "# Generate top 10 user recommendations for each song\n",
    "\n",
    "#songRecs = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### THIS WILL BE REMOVED ####\n",
    "\n",
    "# Generate top 10 movie recommendations for a specified set of users\n",
    "users = train_df.select(als.getUserCol()).distinct().limit(3)\n",
    "userSubsetRecs = model.recommendForUserSubset(users, 10)\n",
    "\n",
    "# Generate top 10 user recommendations for a specified set of movies\n",
    "# songs = df_dropped.select(als.getItemCol()).distinct().limit(3)\n",
    "# songSubSetRecs = model.recommendForItemSubset(songs, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userSubsetRecs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = userSubsetRecs.select(userSubsetRecs.user_id_numer,explode(userSubsetRecs.recommendations.track_id_numer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "flatten_df = exploded_df.groupby('user_id_numer').agg(func.collect_list('col').alias(\"col\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{262469: [50608, 35076, 4576, 5314, 22981, 62245, 54627, 15646, 22906, 104581],\n",
       " 45953: [54627, 62245, 16999, 50608, 31340, 23388, 25461, 9782, 67491, 15646],\n",
       " 278371: [50608, 28588, 37291, 5314, 48884, 16901, 46876, 10896, 28633, 95422]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dict = flatten_df.collect()\n",
    "df_dict = [{r['user_id_numer']: r['col']} for r in df_dict]\n",
    "dict((key,d[key]) for d in df_dict for key in d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-------------+--------------+------------+\n",
      "|count|__index_level_0__|user_id_numer|track_id_numer|  prediction|\n",
      "+-----+-----------------+-------------+--------------+------------+\n",
      "|    1|           580845|     199743.0|         148.0|  -0.7401133|\n",
      "|    1|          1104504|     289603.0|        2366.0|   1.1883036|\n",
      "|    7|           831326|      74503.0|        6397.0|  -1.0921481|\n",
      "|    1|           766988|      71392.0|       47711.0|    3.418543|\n",
      "|    2|           182190|     130992.0|       75509.0| -0.29655308|\n",
      "|    1|           388396|     166437.0|         243.0|  -0.3623914|\n",
      "|    2|           132892|     122534.0|         897.0|   0.4828575|\n",
      "|    3|          1220240|     309456.0|        1896.0|   0.6342591|\n",
      "|    4|           295321|     150190.0|       18218.0|   1.2568204|\n",
      "|    1|           878538|     250951.0|       20396.0|  0.26326305|\n",
      "|    1|           105528|     117867.0|       48686.0| -0.31276146|\n",
      "|    1|            83334|     113915.0|       67086.0|-0.114462465|\n",
      "|    3|          1253265|      94436.0|      100615.0| -0.19176124|\n",
      "|    1|           969300|     266532.0|          31.0| -0.67162806|\n",
      "|    4|           759745|     230647.0|          31.0|  -0.0649762|\n",
      "|    3|           527709|     190721.0|          31.0|  0.17861372|\n",
      "|    3|          1103699|     289471.0|        1352.0|  0.94388103|\n",
      "|    2|           331349|     156391.0|        1352.0|-0.042472925|\n",
      "|    2|           846418|     245486.0|        1618.0|  0.49307817|\n",
      "|    2|           888275|     252788.0|        1650.0| -0.30645508|\n",
      "+-----+-----------------+-------------+--------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test run\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+-------------+--------------+----------+\n",
      "|count|__index_level_0__|user_id_numer|track_id_numer|prediction|\n",
      "+-----+-----------------+-------------+--------------+----------+\n",
      "|   30|           170110|     129021.0|        4159.0| 29.096352|\n",
      "|    2|           659877|     213424.0|       18607.0| 25.425692|\n",
      "|    1|           157695|      42701.0|        1288.0| 24.202473|\n",
      "|    5|          1322196|     327200.0|        1302.0| 20.751654|\n",
      "|    2|          1210818|      92410.0|        2454.0| 14.304222|\n",
      "|    2|           404513|      54220.0|       11505.0| 13.979452|\n",
      "|   14|          1356530|     332963.0|        1080.0| 12.923365|\n",
      "|    1|           943694|     262160.0|        2427.0| 10.379565|\n",
      "|   11|          1324320|      97854.0|       21793.0|  9.898027|\n",
      "|    1|             5265|      35694.0|       13421.0|  9.275231|\n",
      "|    2|          1081617|     285600.0|       12344.0|  8.869305|\n",
      "|    2|          1125287|     292864.0|        6054.0|  8.486488|\n",
      "|   26|           511306|     187728.0|        6757.0|  8.424592|\n",
      "|    5|           698322|     220209.0|        7114.0|  8.053871|\n",
      "|   15|          1304532|     324324.0|       14875.0|  7.966901|\n",
      "|    6|           415664|     171174.0|        8505.0| 7.7074695|\n",
      "|   16|           826652|     242101.0|       10369.0| 7.4832096|\n",
      "|   11|          1213813|     308317.0|        2120.0| 7.4032416|\n",
      "|    9|          1050203|     280098.0|        8368.0|  7.372878|\n",
      "|    6|           449304|     177182.0|       10895.0|  7.354228|\n",
      "+-----+-----------------+-------------+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_df)\n",
    "predictions.orderBy('prediction', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ctx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-04358db8eb7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRegressionMetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRankingMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRankingMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/mllib/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, predictionAndLabels)\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictionAndLabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictionAndLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m         \u001b[0msql_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         df = sql_ctx.createDataFrame(predictionAndLabels,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1644\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1645\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ctx'"
     ]
    }
   ],
   "source": [
    "#https://stackoverflow.com/questions/59390481/how-to-implement-ranking-metrics-of-pyspark\n",
    "\n",
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "metrics = RankingMetrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+\n",
      "|user_id_numer|     recommendations|\n",
      "+-------------+--------------------+\n",
      "|       323090|[{4576, 104.34744...|\n",
      "|       314281|[{11827, 10.25488...|\n",
      "|       227152|[{10896, 25.36068...|\n",
      "|       133153|[{50608, 254.1710...|\n",
      "|        35694|[{50608, 284.8812...|\n",
      "|        92644|[{25176, 58.62921...|\n",
      "|       165914|[{11827, 21.78151...|\n",
      "|       136625|[{16999, 43.67716...|\n",
      "|       225755|[{50608, 84.67899...|\n",
      "|       287645|[{48884, 180.0310...|\n",
      "|       208696|[{28588, 1002.882...|\n",
      "|       275698|[{11827, 241.7612...|\n",
      "|       167242|[{11827, 241.0525...|\n",
      "|       118605|[{1757, 27.664623...|\n",
      "|       258065|[{54627, 16.34184...|\n",
      "|        23136|[{50608, 96.51617...|\n",
      "|       157866|[{9831, 56.422874...|\n",
      "|       274716|[{48884, 195.6008...|\n",
      "|       229338|[{1757, 156.13522...|\n",
      "|       245018|[{4576, 9.095392}...|\n",
      "+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test = model.recommendForUserSubset(test_df,10)\n",
    "test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\n",
    "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
