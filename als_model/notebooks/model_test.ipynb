{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b3b477f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users selected\n",
      "test preds df created\n",
      "test true df created\n",
      "RDD created\n",
      "Ranking Metrics called\n",
      "0.004575744850017291\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.mllib.evaluation import RankingMetrics\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def main(spark, sc):\n",
    "\n",
    "    # load test df\n",
    "\n",
    "    test_df = spark.read.parquet('/Users/harlanhutton/Documents/NYU 1/Second Sem/Big Data/Labs/final/final-project-recommender-systers/baseline_model/test_df_1.parquet')\n",
    "    test_df.createOrReplaceTempView('test_df')\n",
    "\n",
    "    # load trained model\n",
    "    model = ALSModel.load('/Users/harlanhutton/Documents/NYU 1/Second Sem/Big Data/Labs/final/final-project-recommender-systers/baseline_model/model')\n",
    "\n",
    "    # Select users from test df\n",
    "    users = test_df.select('user_id_numer').distinct()\n",
    "\n",
    "    print('users selected')\n",
    "\n",
    "    # Create predictions for test users\n",
    "    test_preds = model.recommendForUserSubset(users,500)\n",
    "    test_preds = test_preds.select(test_preds.user_id_numer,func.explode(test_preds.recommendations.track_id_numer))\n",
    "    test_preds = test_preds.groupby('user_id_numer').agg(func.collect_list('col').alias(\"col\"))\n",
    "\n",
    "    print('test preds df created')\n",
    "    \n",
    "    # Create dataframe for true test user listens\n",
    "    test_true = test_df.groupby('user_id_numer').agg(func.collect_list('track_id_numer').alias(\"track_id_numer\"))\n",
    "\n",
    "    print('test true df created')\n",
    " \n",
    "    # Create RDD of predictions and true listens\n",
    "    recs_and_true_RDD = (test_preds.join(test_true, 'user_id_numer').rdd.map(lambda row: (row[1], row[2])))\n",
    "\n",
    "    print('RDD created')\n",
    "    \n",
    "    # Call Ranking Metrics on predictions and true\n",
    "    metrics = RankingMetrics(recs_and_true_RDD)\n",
    "\n",
    "    print(\"Ranking Metrics called\")\n",
    "\n",
    "    # Get Mean Average Precision\n",
    "    MAP = metrics.meanAveragePrecision\n",
    "    print(MAP)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    spark = SparkSession.builder.config('spark.driver.memory', '16g')\\\n",
    "    .appName('model test').getOrCreate()\n",
    "    \n",
    "    # Create spark context\n",
    "    sc = spark.sparkContext\n",
    "    \n",
    "    # Call main function\n",
    "    main(spark, sc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
